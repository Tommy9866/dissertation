{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df =  pd.read_csv('dataset/brain_stroke.csv')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "file_prefix = \"plane\"  # Change this to any word you like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Identify categorical data (change this based on your actual data)\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_cols:\n",
    "    # Ensure the column is of type object (string) or category\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "        \n",
    "df['Y'], unique = pd.factorize(df['Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.15</td>\n",
       "      <td>29.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>191.15</td>\n",
       "      <td>31.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95.02</td>\n",
       "      <td>31.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.94</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.75</td>\n",
       "      <td>29.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4981 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0          1  67.0             0              1             1          1   \n",
       "1          1  80.0             0              1             1          1   \n",
       "2          0  49.0             0              0             1          1   \n",
       "3          0  79.0             1              0             1          2   \n",
       "4          1  81.0             0              0             1          1   \n",
       "...      ...   ...           ...            ...           ...        ...   \n",
       "4976       1  41.0             0              0             0          1   \n",
       "4977       1  40.0             0              0             1          1   \n",
       "4978       0  45.0             1              0             1          0   \n",
       "4979       1  40.0             0              0             1          1   \n",
       "4980       0  80.0             1              0             1          1   \n",
       "\n",
       "      Residence_type  avg_glucose_level   bmi  smoking_status  Y  \n",
       "0                  1             228.69  36.6               1  0  \n",
       "1                  0             105.92  32.5               2  0  \n",
       "2                  1             171.23  34.4               3  0  \n",
       "3                  0             174.12  24.0               2  0  \n",
       "4                  1             186.21  29.0               1  0  \n",
       "...              ...                ...   ...             ... ..  \n",
       "4976               0              70.15  29.8               1  1  \n",
       "4977               1             191.15  31.1               3  1  \n",
       "4978               0              95.02  31.8               3  1  \n",
       "4979               0              83.94  30.0               3  1  \n",
       "4980               1              83.75  29.1               2  1  \n",
       "\n",
       "[4981 rows x 11 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624\n",
      "[LightGBM] [Info] Number of data points in the train set: 3188, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951066 -> initscore=2.967122\n",
      "[LightGBM] [Info] Start training from score 2.967122\n",
      "[LightGBM] [Info] Number of positive: 3790, number of negative: 194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 626\n",
      "[LightGBM] [Info] Number of data points in the train set: 3984, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951305 -> initscore=2.972263\n",
      "[LightGBM] [Info] Start training from score 2.972263\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 630\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 3188, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951066 -> initscore=2.967122\n",
      "[LightGBM] [Info] Start training from score 2.967122\n",
      "[LightGBM] [Info] Number of positive: 3790, number of negative: 194\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 633\n",
      "[LightGBM] [Info] Number of data points in the train set: 3984, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951305 -> initscore=2.972263\n",
      "[LightGBM] [Info] Start training from score 2.972263\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624\n",
      "[LightGBM] [Info] Number of data points in the train set: 3188, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951066 -> initscore=2.967122\n",
      "[LightGBM] [Info] Start training from score 2.967122\n",
      "[LightGBM] [Info] Number of positive: 3790, number of negative: 194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 626\n",
      "[LightGBM] [Info] Number of data points in the train set: 3984, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951305 -> initscore=2.972263\n",
      "[LightGBM] [Info] Start training from score 2.972263\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 624\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 624\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 622\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 623\n",
      "[LightGBM] [Info] Number of data points in the train set: 3188, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951066 -> initscore=2.967122\n",
      "[LightGBM] [Info] Start training from score 2.967122\n",
      "[LightGBM] [Info] Number of positive: 3790, number of negative: 194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 625\n",
      "[LightGBM] [Info] Number of data points in the train set: 3984, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951305 -> initscore=2.972263\n",
      "[LightGBM] [Info] Start training from score 2.972263\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 630\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 156\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 3188, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951066 -> initscore=2.967122\n",
      "[LightGBM] [Info] Start training from score 2.967122\n",
      "[LightGBM] [Info] Number of positive: 3790, number of negative: 194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 633\n",
      "[LightGBM] [Info] Number of data points in the train set: 3984, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951305 -> initscore=2.972263\n",
      "[LightGBM] [Info] Start training from score 2.972263\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 156\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 3188, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951066 -> initscore=2.967122\n",
      "[LightGBM] [Info] Start training from score 2.967122\n",
      "[LightGBM] [Info] Number of positive: 3790, number of negative: 194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36\n",
      "[LightGBM] [Info] Number of data points in the train set: 3984, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951305 -> initscore=2.972263\n",
      "[LightGBM] [Info] Start training from score 2.972263\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 632\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 630\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951365 -> initscore=2.973553\n",
      "[LightGBM] [Info] Start training from score 2.973553\n",
      "[LightGBM] [Info] Number of positive: 3032, number of negative: 156\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 3188, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951066 -> initscore=2.967122\n",
      "[LightGBM] [Info] Start training from score 2.967122\n",
      "[LightGBM] [Info] Number of positive: 3790, number of negative: 194\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 633\n",
      "[LightGBM] [Info] Number of data points in the train set: 3984, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.951305 -> initscore=2.972263\n",
      "[LightGBM] [Info] Start training from score 2.972263\n",
      "Average Improvement by Transformation:\n",
      "  Transformation  CV Improvement  Test Improvement\n",
      "3         Robust    1.290869e-03         -0.001003\n",
      "1         MinMax    1.183323e-03         -0.001003\n",
      "5    Yeo-Johnson    7.892573e-04         -0.000860\n",
      "4       Standard    7.171545e-04         -0.001003\n",
      "2       Quantile    2.153625e-04         -0.000287\n",
      "0        Binning    4.953969e-07         -0.003439\n",
      "\n",
      "Top 10 Model-Transformation Combinations (based on CV Improvement):\n",
      "   Transformation              Model  CV Improvement  Test Improvement\n",
      "30        Binning      Decision Tree        0.008283         -0.016048\n",
      "8          MinMax                KNN        0.005775         -0.002006\n",
      "15         Robust                KNN        0.005523         -0.005015\n",
      "36       Quantile                KNN        0.005021          0.001003\n",
      "1        Standard                KNN        0.004268         -0.001003\n",
      "22    Yeo-Johnson                KNN        0.003766         -0.001003\n",
      "32        Binning  Gradient Boosting        0.003263         -0.003009\n",
      "16         Robust      Decision Tree        0.002761         -0.001003\n",
      "23    Yeo-Johnson      Decision Tree        0.002512         -0.001003\n",
      "13         MinMax           LightGBM        0.002259          0.000000\n",
      "\n",
      "Best Combination:\n",
      "Transformation: Binning\n",
      "Model: Decision Tree\n",
      "No Scaling CV Accuracy: 0.9036\n",
      "Transformation CV Accuracy: 0.9119\n",
      "CV Improvement: 0.0083\n",
      "No Scaling Test Accuracy: 0.9208\n",
      "Transformation Test Accuracy: 0.9047\n",
      "Test Improvement: -0.0160\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Assuming 'df' is your dataframe and 'Y' is your target column\n",
    "X = df.drop('Y', axis=1)\n",
    "y = df['Y']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a custom binning function that works on DataFrames\n",
    "def custom_binning(df):\n",
    "    return df.apply(lambda x: pd.qcut(x, q=10, labels=False, duplicates='drop'))\n",
    "\n",
    "# Define transformations\n",
    "transformations = {\n",
    "    'No Scaling': FunctionTransformer(lambda x: x),\n",
    "    'Standard': StandardScaler(),\n",
    "    'MinMax': MinMaxScaler(),\n",
    "    'Robust': RobustScaler(),\n",
    "    'Yeo-Johnson': PowerTransformer(method='yeo-johnson', standardize=True),\n",
    "    'Binning': FunctionTransformer(custom_binning),\n",
    "    'Quantile': QuantileTransformer(output_distribution='normal')\n",
    "}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'LightGBM': LGBMClassifier(),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Test each combination of transformation and model\n",
    "for trans_name, transformer in transformations.items():\n",
    "    for model_name, model in models.items():\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('transformer', transformer),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        mean_cv_score = np.mean(cv_scores)\n",
    "        \n",
    "        # Fit on the entire training set and evaluate on test set\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        test_score = pipeline.score(X_test, y_test)\n",
    "        \n",
    "        results.append({\n",
    "            'Transformation': trans_name,\n",
    "            'Model': model_name,\n",
    "            'CV Mean Accuracy': mean_cv_score,\n",
    "            'Test Accuracy': test_score\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Extract the \"No Scaling\" results for comparison\n",
    "no_scaling_results = results_df[results_df['Transformation'] == 'No Scaling']\n",
    "\n",
    "# Compare each transformation to \"No Scaling\"\n",
    "comparison_results = []\n",
    "for trans_name in transformations.keys():\n",
    "    if trans_name == 'No Scaling':\n",
    "        continue\n",
    "    trans_results = results_df[results_df['Transformation'] == trans_name]\n",
    "    for model_name in models.keys():\n",
    "        no_scaling_cv = no_scaling_results[no_scaling_results['Model'] == model_name]['CV Mean Accuracy'].values[0]\n",
    "        trans_cv = trans_results[trans_results['Model'] == model_name]['CV Mean Accuracy'].values[0]\n",
    "        no_scaling_test = no_scaling_results[no_scaling_results['Model'] == model_name]['Test Accuracy'].values[0]\n",
    "        trans_test = trans_results[trans_results['Model'] == model_name]['Test Accuracy'].values[0]\n",
    "        cv_improvement = trans_cv - no_scaling_cv\n",
    "        test_improvement = trans_test - no_scaling_test\n",
    "        comparison_results.append({\n",
    "            'Transformation': trans_name,\n",
    "            'Model': model_name,\n",
    "            'No Scaling CV Accuracy': no_scaling_cv,\n",
    "            'Transformation CV Accuracy': trans_cv,\n",
    "            'CV Improvement': cv_improvement,\n",
    "            'No Scaling Test Accuracy': no_scaling_test,\n",
    "            'Transformation Test Accuracy': trans_test,\n",
    "            'Test Improvement': test_improvement\n",
    "        })\n",
    "\n",
    "# Convert comparison results to a DataFrame\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Compute average improvement for each transformation\n",
    "average_improvement = comparison_df.groupby('Transformation')[['CV Improvement', 'Test Improvement']].mean().reset_index()\n",
    "average_improvement = average_improvement.sort_values('CV Improvement', ascending=False)\n",
    "\n",
    "# Display the average improvement\n",
    "print(\"Average Improvement by Transformation:\")\n",
    "print(average_improvement)\n",
    "\n",
    "# Display the top 10 results based on CV Improvement\n",
    "comparison_df = comparison_df.sort_values('CV Improvement', ascending=False)\n",
    "print(\"\\nTop 10 Model-Transformation Combinations (based on CV Improvement):\")\n",
    "print(comparison_df[['Transformation', 'Model', 'CV Improvement', 'Test Improvement']].head(10))\n",
    "\n",
    "# Get the best transformation and model combination\n",
    "best_combination = comparison_df.iloc[0]\n",
    "print(f\"\\nBest Combination:\")\n",
    "print(f\"Transformation: {best_combination['Transformation']}\")\n",
    "print(f\"Model: {best_combination['Model']}\")\n",
    "print(f\"No Scaling CV Accuracy: {best_combination['No Scaling CV Accuracy']:.4f}\")\n",
    "print(f\"Transformation CV Accuracy: {best_combination['Transformation CV Accuracy']:.4f}\")\n",
    "print(f\"CV Improvement: {best_combination['CV Improvement']:.4f}\")\n",
    "print(f\"No Scaling Test Accuracy: {best_combination['No Scaling Test Accuracy']:.4f}\")\n",
    "print(f\"Transformation Test Accuracy: {best_combination['Transformation Test Accuracy']:.4f}\")\n",
    "print(f\"Test Improvement: {best_combination['Test Improvement']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully in the 'result/transformation' directory with prefix 'stroke'.\n"
     ]
    }
   ],
   "source": [
    "# New cell\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# Add rank column to average_improvement\n",
    "average_improvement['Rank'] = average_improvement['CV Improvement'].rank(ascending=False, method='min')\n",
    "average_improvement = average_improvement.sort_values('Rank')\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs('result/transformation', exist_ok=True)\n",
    "\n",
    "# Save average_improvement as CSV\n",
    "average_improvement.to_csv(f'result/transformation/classification/{file_prefix}_average.csv', index=False)\n",
    "\n",
    "# Save comparison_df as CSV\n",
    "comparison_df.to_csv(f'result/transformation/classification/{file_prefix}_compared.csv', index=False)\n",
    "\n",
    "print(f\"Files saved successfully in the 'result/transformation' directory with prefix '{file_prefix}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
